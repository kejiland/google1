#!/usr/bin/env python3
"""
GitHub è‡ªåŠ¨èŠ‚ç‚¹è¿‡æ»¤å™¨ - ä¿®æ­£ç‰ˆ
åŠŸèƒ½ï¼šåªç§»é™¤ http=ã€https=ã€socks5= å¼€å¤´çš„èŠ‚ç‚¹
ä¿ç•™æ‰€æœ‰æ ‡å‡†ä»£ç†èŠ‚ç‚¹æ ¼å¼
"""

import requests
import os
from datetime import datetime
import logging

# é…ç½®
SOURCE_URL = "https://raw.githubusercontent.com/Graysongon/google/refs/heads/main/%E4%B8%AA%E4%BA%BA"
OUTPUT_FILE = "kejiland.txt"
LOG_FILE = "filter.log"

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def fetch_nodes():
    """ä»æºåœ°å€è·å–èŠ‚ç‚¹æ•°æ®"""
    try:
        logger.info(f"ğŸ“¡ æ­£åœ¨ä»æºåœ°å€è·å–æ•°æ®...")
        response = requests.get(SOURCE_URL, timeout=30)
        response.raise_for_status()
        
        response.encoding = response.apparent_encoding or 'utf-8'
        content = response.text
        lines = content.splitlines()
        
        logger.info(f"âœ… è·å–æˆåŠŸï¼å…± {len(lines)} è¡Œæ•°æ®")
        
        # æ˜¾ç¤ºæ•°æ®æ ¼å¼åˆ†æ
        logger.info("ğŸ“‹ æ•°æ®æ ¼å¼åˆ†æ:")
        protocols = {}
        for line in lines:
            if line.strip():
                # æå–åè®®éƒ¨åˆ†
                if '://' in line:
                    protocol = line.split('://')[0].lower()
                elif '=' in line:
                    protocol = line.split('=')[0].strip().lower()
                else:
                    continue
                
                protocols[protocol] = protocols.get(protocol, 0) + 1
        
        for protocol, count in sorted(protocols.items()):
            logger.info(f"  {protocol}: {count} ä¸ª")
        
        return content
    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
        return None

def filter_nodes(content):
    """è¿‡æ»¤èŠ‚ç‚¹ï¼Œåªç§»é™¤ http=ã€https=ã€socks5= å¼€å¤´çš„è¡Œ"""
    if not content:
        return None
    
    lines = content.splitlines()
    filtered_lines = []
    removed_count = 0
    
    # è¦ç§»é™¤çš„åè®®ï¼ˆåªæœ‰è¿™ä¸‰ç§æ ¼å¼ä½¿ç”¨ =ï¼‰
    remove_protocols = ['http=', 'https=', 'socks5=']
    
    logger.info("ğŸ” å¼€å§‹è¿‡æ»¤èŠ‚ç‚¹...")
    
    for i, line in enumerate(lines):
        line_stripped = line.strip()
        
        if not line_stripped:
            filtered_lines.append(line)
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯éœ€è¦ç§»é™¤çš„åè®®ï¼ˆä½¿ç”¨ = æ ¼å¼ï¼‰
        should_remove = False
        for protocol in remove_protocols:
            if line_stripped.lower().startswith(protocol):
                should_remove = True
                removed_count += 1
                
                if removed_count <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªè¢«è¿‡æ»¤çš„
                    logger.debug(f"ç§»é™¤ {protocol}: {line_stripped[:60]}...")
                break
        
        if should_remove:
            continue
        
        # ä¿ç•™æ‰€æœ‰å…¶ä»–è¡Œï¼ˆåŒ…æ‹¬æ ‡å‡†æ ¼å¼ ss://, vmess:// ç­‰ï¼‰
        filtered_lines.append(line)
    
    logger.info(f"ğŸ“Š è¿‡æ»¤ç»Ÿè®¡:")
    logger.info(f"  åŸå§‹è¡Œæ•°: {len(lines)}")
    logger.info(f"  ç§»é™¤è¡Œæ•°: {removed_count} (http=/https=/socks5=)")
    logger.info(f"  ä¿ç•™è¡Œæ•°: {len(filtered_lines)}")
    
    # åˆ†æä¿ç•™çš„èŠ‚ç‚¹æ ¼å¼
    analyze_preserved_nodes(filtered_lines)
    
    return '\n'.join(filtered_lines)

def analyze_preserved_nodes(lines):
    """åˆ†æä¿ç•™çš„èŠ‚ç‚¹ç±»å‹"""
    standard_protocols = {
        'ss://': 0,
        'vmess://': 0,
        'vless://': 0,
        'trojan://': 0,
        'ssr://': 0,
        'å…¶ä»–æ ¼å¼': 0
    }
    
    for line in lines:
        line_stripped = line.strip()
        if not line_stripped:
            continue
        
        line_lower = line_stripped.lower()
        
        # æ£€æŸ¥æ ‡å‡†æ ¼å¼
        found = False
        for protocol in standard_protocols:
            if line_lower.startswith(protocol):
                standard_protocols[protocol] += 1
                found = True
                break
        
        if not found:
            standard_protocols['å…¶ä»–æ ¼å¼'] += 1
    
    logger.info("ğŸ“‹ ä¿ç•™èŠ‚ç‚¹æ ¼å¼åˆ†æ:")
    total_preserved = sum(standard_protocols.values())
    for protocol, count in standard_protocols.items():
        if count > 0:
            percentage = count / total_preserved * 100 if total_preserved > 0 else 0
            logger.info(f"  {protocol}: {count} ä¸ª ({percentage:.1f}%)")
    
    # æ˜¾ç¤ºä¿ç•™çš„èŠ‚ç‚¹ç¤ºä¾‹
    logger.info("ğŸ“ ä¿ç•™èŠ‚ç‚¹ç¤ºä¾‹ (å‰5ä¸ª):")
    example_count = 0
    for line in lines:
        line_stripped = line.strip()
        if line_stripped and example_count < 5:
            logger.info(f"  {line_stripped[:80]}...")
            example_count += 1

def save_result(content):
    """ä¿å­˜è¿‡æ»¤åçš„ç»“æœåˆ°æ–‡ä»¶"""
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ç°æœ‰å†…å®¹ç›¸åŒ
        existing_content = ""
        if os.path.exists(OUTPUT_FILE):
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                existing_content = f.read()
        
        if content == existing_content:
            logger.info("ğŸ“Œ å†…å®¹æ— å˜åŒ–ï¼Œæ— éœ€æ›´æ–°æ–‡ä»¶")
            return False
        
        # å†™å…¥æ–°å†…å®¹
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(content)
        
        file_size = os.path.getsize(OUTPUT_FILE)
        logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {OUTPUT_FILE}")
        logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        logger.info(f"ğŸ“„ æ–‡ä»¶è¡Œæ•°: {len(content.splitlines())}")
        
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return False

def verify_result():
    """éªŒè¯è¿‡æ»¤ç»“æœ"""
    try:
        if not os.path.exists(OUTPUT_FILE):
            logger.error("è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.splitlines()
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰éœ€è¦ç§»é™¤çš„å†…å®¹
        bad_lines = []
        for line in lines:
            line_stripped = line.strip()
            if line_stripped:
                line_lower = line_stripped.lower()
                if (line_lower.startswith('http=') or 
                    line_lower.startswith('https=') or 
                    line_lower.startswith('socks5=')):
                    bad_lines.append(line)
        
        if not bad_lines:
            logger.info("âœ… éªŒè¯é€šè¿‡ï¼šæ—  http=/https=/socks5= èŠ‚ç‚¹")
            return True
        else:
            logger.warning(f"âš ï¸  å‘ç° {len(bad_lines)} ä¸ªæœªè¿‡æ»¤çš„èŠ‚ç‚¹:")
            for bad_line in bad_lines[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                logger.warning(f"  - {bad_line[:60]}...")
            return False
            
    except Exception as e:
        logger.error(f"éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info(f"ğŸš€ GitHub èŠ‚ç‚¹è¿‡æ»¤å™¨å¯åŠ¨")
    logger.info(f"ğŸ• æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    # 1. è·å–æ•°æ®
    raw_content = fetch_nodes()
    if not raw_content:
        logger.error("æ— æ³•è·å–æ•°æ®ï¼Œç¨‹åºç»ˆæ­¢")
        return False
    
    # 2. è¿‡æ»¤èŠ‚ç‚¹
    filtered_content = filter_nodes(raw_content)
    if not filtered_content:
        logger.error("è¿‡æ»¤å¤±è´¥")
        return False
    
    # 3. ä¿å­˜ç»“æœ
    if not save_result(filtered_content):
        logger.info("æ²¡æœ‰æ–°å†…å®¹æ›´æ–°")
    
    # 4. éªŒè¯ç»“æœ
    verify_result()
    
    logger.info("=" * 60)
    logger.info("ğŸ‰ ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    logger.info("=" * 60)
    
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
